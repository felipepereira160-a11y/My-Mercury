import streamlit as st
import google.generativeai as genai
import pandas as pd
import numpy as np
import os
from datetime import datetime
from haversine import haversine, Unit

# ============================================================
# CONFIGURA√á√ÉO GERAL DO APP
# ============================================================
st.set_page_config(page_title="Merc√∫rio IA", page_icon="üß†", layout="wide")
st.title("üß† Merc√∫rio IA")
st.write("Fa√ßa o upload de seus arquivos na barra lateral e converse com a IA!")

# ------------------------------------------------------------
# CONFIGURA√á√ÉO DA CHAVE DE API
# ------------------------------------------------------------
api_key = st.secrets.get("GOOGLE_API_KEY") or os.environ.get("GOOGLE_API_KEY")
api_key_status = "‚úîÔ∏è Carregada" if api_key else "‚ùå ERRO: Chave n√£o encontrada."
st.sidebar.caption(f"**Status da Chave de API:** {api_key_status}")

if not api_key:
    st.error("A chave da API do Google n√£o foi encontrada. O aplicativo n√£o pode funcionar.")
    st.stop()

genai.configure(api_key=api_key)
modelo_fixo = "gemini-2.5-flash"  # sempre o modelo mais econ√¥mico

# ------------------------------------------------------------
# ESTADOS DA SESS√ÉO
# ------------------------------------------------------------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "model" not in st.session_state:
    st.session_state.model = genai.GenerativeModel(modelo_fixo)
if "df_dados" not in st.session_state:
    st.session_state.df_dados = None
if "df_mapeamento" not in st.session_state:
    st.session_state.df_mapeamento = None
if "df_devolucao" not in st.session_state:
    st.session_state.df_devolucao = None
if "df_pagamento" not in st.session_state:
    st.session_state.df_pagamento = None

# ------------------------------------------------------------
# FUN√á√ïES AUXILIARES
# ------------------------------------------------------------
@st.cache_data
def convert_df_to_csv(df):
    return df.to_csv(index=False, sep=';').encode('utf-8-sig')

def carregar_dataframe(arquivo, sep=','):
    nome = arquivo.name.lower()
    try:
        if nome.endswith(('.xlsx', '.xls')):
            return pd.read_excel(arquivo, engine='openpyxl')
        elif nome.endswith('.csv'):
            arquivo.seek(0)
            return pd.read_csv(arquivo, encoding='latin-1', sep=sep, on_bad_lines='skip')
    except Exception as e:
        st.error(f"Erro ao carregar {arquivo.name}: {e}")
    return None

# ------------------------------------------------------------
# UPLOAD DE ARQUIVOS
# ------------------------------------------------------------
st.sidebar.header("üìÇ Base de Conhecimento")
tipos = ["csv", "xlsx", "xls"]

with st.sidebar:
    data_file = st.file_uploader("1Ô∏è‚É£ Agendamentos (OS)", type=tipos)
    if data_file: st.session_state.df_dados = carregar_dataframe(data_file, ';')

    map_file = st.file_uploader("2Ô∏è‚É£ Mapeamento de RT", type=tipos)
    if map_file: st.session_state.df_mapeamento = carregar_dataframe(map_file, ',')

    dev_file = st.file_uploader("3Ô∏è‚É£ Itens a Instalar (Devolu√ß√£o)", type=tipos)
    if dev_file: st.session_state.df_devolucao = carregar_dataframe(dev_file, ';')

    pag_file = st.file_uploader("4Ô∏è‚É£ Base de Pagamento (Duplicidade)", type=tipos)
    if pag_file: st.session_state.df_pagamento = carregar_dataframe(pag_file, ';')

    if st.button("üßπ Limpar Tudo"):
        st.session_state.clear()
        st.rerun()

# ------------------------------------------------------------
# DETEC√á√ÉO DE INTEN√á√ÉO (CHAT ou DADOS)
# ------------------------------------------------------------
def detectar_tipo_pergunta(texto):
    texto = texto.lower()
    palavras_dados = [
        "tabela", "csv", "coluna", "quantos", "linhas", "ordem", "agendamento",
        "representante", "rt", "valor", "duplicidade", "proximidade", "servi√ßo",
        "dados", "planilha", "base", "arquivo", "excel"
    ]
    if any(p in texto for p in palavras_dados):
        return "dados"
    return "chat"

# ------------------------------------------------------------
# AN√ÅLISE DE DADOS (modo seguro)
# ------------------------------------------------------------
def executar_analise(prompt, df):
    try:
        prompt_engenharia = f"""
        Voc√™ √© um especialista em Python e Pandas.
        Gere uma resposta curta e objetiva baseada no DataFrame `df` abaixo.
        Colunas dispon√≠veis: {', '.join(df.columns)}
        Pergunta: {prompt}
        Retorne apenas a resposta em texto simples, sem gerar c√≥digo Python.
        """
        resposta = st.session_state.model.generate_content(prompt_engenharia)
        return resposta.text.strip()
    except Exception as e:
        return f"Erro na an√°lise: {e}"

# ============================================================
# CHAT INTERATIVO MERC√öRIO IA
# ============================================================
st.markdown("---")
st.header("üí¨ Chat com o Assistente Merc√∫rio IA")

# Exibir hist√≥rico do chat
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Entrada do usu√°rio
if prompt := st.chat_input("Envie uma pergunta ou mensagem..."):
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    tipo = detectar_tipo_pergunta(prompt)
    resposta_final = ""

    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            if tipo == "dados":
                df = st.session_state.df_dados or st.session_state.df_mapeamento
                if df is not None:
                    resposta_final = executar_analise(prompt, df)
                else:
                    resposta_final = "Nenhum arquivo foi carregado ainda para an√°lise de dados."
            else:
                resposta = st.session_state.model.generate_content(prompt)
                resposta_final = resposta.text.strip()

            st.markdown(resposta_final)

    st.session_state.chat_history.append({"role": "assistant", "content": resposta_final})
