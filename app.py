import streamlit as st
import google.generativeai as genai
import pandas as pd

# Configura o t√≠tulo da p√°gina, layout e um √≠cone
st.set_page_config(
    page_title="Seu Analista de Dados com IA",
    page_icon="üìä",
    layout="wide"
)

# --- T√≠tulo Principal ---
st.title("üìä Mercury EEEEEEEEO")
st.write("Converse comigo ou fa√ßa o upload de um arquivo na barra lateral para come√ßar a analisar!")

# --- Configura√ß√£o da API Key ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except Exception as e:
    st.error("Chave de API do Google n√£o configurada. Por favor, adicione-a aos segredos do seu app no Streamlit.")
    st.stop()

# --- Barra Lateral para Upload ---
with st.sidebar:
    st.header("Adicionar Conhecimento")
    uploaded_file = st.sidebar.file_uploader(
        "Fa√ßa o upload de um arquivo CSV ou XLSX", 
        type=["csv", "xlsx"]
    )

    if 'dataframe' not in st.session_state:
        st.session_state.dataframe = None

    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file, encoding='latin-1', sep=';', on_bad_lines='skip')
            elif uploaded_file.name.endswith('.xlsx'):
                df = pd.read_excel(uploaded_file, engine='openpyxl')
            st.session_state.dataframe = df
            st.success("Arquivo carregado com sucesso!")
        except Exception as e:
            st.error(f"Erro ao ler o arquivo: {e}")
    
    if st.button("Limpar Arquivo e Chat"):
        st.session_state.dataframe = None
        st.session_state.chat = model.start_chat(history=[])
        st.rerun()

# --- Corpo Principal da Aplica√ß√£o ---
model = genai.GenerativeModel('gemini-pro-latest')
if "chat" not in st.session_state:
    st.session_state.chat = model.start_chat(history=[])

if st.session_state.dataframe is not None:
    df = st.session_state.dataframe
    st.header("Dashboard do Arquivo")
    col1, col2, col3 = st.columns(3)
    col1.metric("Total de Linhas", f"{df.shape[0]:,}".replace(",", "."), "linhas")
    col2.metric("Total de Colunas", f"{df.shape[1]}", "colunas")
    coluna_cliente = next((col for col in df.columns if 'cliente' in col.lower()), None)
    if coluna_cliente:
        clientes_unicos = df[coluna_cliente].nunique()
        col3.metric("Clientes √önicos", f"{clientes_unicos}", "clientes")
    with st.expander("Clique aqui para ver a pr√©-visualiza√ß√£o dos dados"):
        st.dataframe(df)
    st.header("Converse com seus Dados")

# Exibi√ß√£o do Hist√≥rico da Conversa
for message in st.session_state.chat.history:
    role = "assistant" if message.role == 'model' else message.role
    with st.chat_message(role):
        st.markdown(message.parts[0].text)

def executar_analise_pandas(df, pergunta):
    prompt_engenharia = f"""
    Voc√™ √© um assistente especialista em Python e Pandas. Sua tarefa √© converter uma pergunta em uma √∫nica linha de c√≥digo Pandas que a responda.
    O dataframe est√° na vari√°vel `df`.
    Aqui est√£o as primeiras linhas do dataframe: {df.head().to_string()}

    REGRAS DE EXECU√á√ÉO (SIGA EM ORDEM):
    1. PRIMEIRO, verifique se a pergunta exige um filtro na coluna 'Status'. As palavras-chave s√£o "agendadas", "realizadas", "n√£o realizadas", "reagendadas".
       - "agendadas" -> `df['Status'] == 'Agendada'`
       - "realizadas" -> `df['Status'] == 'Realizada'`
       - "n√£o realizadas" -> `df['Status'] == 'Nao Realizada'`
       - "reagendadas" -> `df['Status'] == 'Reagendamento'`
    2. SEGUNDO, aplique a opera√ß√£o principal (contar, somar, agrupar, etc.) ao dataframe J√Å FILTRADO (se a regra 1 se aplicar).

    Pergunta do usu√°rio: "{pergunta}"
    
    Baseado na pergunta e nas REGRAS, gere apenas a linha de c√≥digo Pandas necess√°ria.
    Exemplos:
    - Pergunta: "top 3 cidades com ordens realizadas" -> Resposta: df[df['Status'] == 'Realizada'].groupby('Cidade Agendamento').size().nlargest(3)
    - Pergunta: "qual a soma do valor de deslocamento para ordens n√£o realizadas?" -> Resposta: df[df['Status'] == 'Nao Realizada']['Valor Deslocamento'].sum()
    """
    try:
        code_response = genai.GenerativeModel('gemini-pro-latest').generate_content(prompt_engenharia)
        codigo_pandas = code_response.text.strip().replace('`', '').replace('python', '').strip()
        resultado = eval(codigo_pandas, {'df': df, 'pd': pd})
        return resultado, None
    except Exception as e:
        return None, f"Ocorreu um erro ao executar a an√°lise: {e}"

if prompt := st.chat_input("Converse com a IA ou fa√ßa uma pergunta sobre seus dados..."):
    # Exibe a mensagem do usu√°rio imediatamente
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Decide qual modo usar: Analista de Dados ou Chatbot Geral
    if st.session_state.dataframe is not None:
        # --- Modo Analista de Dados ---
        resultado_analise, erro = executar_analise_pandas(st.session_state.dataframe, prompt)
        
        if erro:
            st.error(erro)
            response_text = "Desculpe, n√£o consegui analisar os dados. Tente uma pergunta mais simples ou verifique o arquivo."
            # Exibe a resposta de erro
            with st.chat_message("assistant"):
                st.markdown(response_text)
            # Adiciona ao hist√≥rico para n√£o sumir
            st.session_state.chat.history.append({'role': 'user', 'parts': [{'text': prompt}]})
            st.session_state.chat.history.append({'role': 'assistant', 'parts': [{'text': response_text}]})
        else:
            # Resposta com base na an√°lise
            response_container = st.chat_message("assistant")
            with response_container:
                if isinstance(resultado_analise, (pd.Series, pd.DataFrame)) and len(resultado_analise) > 1:
                    st.write("Aqui est√° uma visualiza√ß√£o para sua pergunta:")
                    st.bar_chart(resultado_analise)
                    prompt_final = f"""A pergunta do usu√°rio foi: "{prompt}". Para responder, um gr√°fico de barras j√° foi exibido na tela. Os dados s√£o: {resultado_analise.to_string()}. Sua tarefa √© escrever uma breve an√°lise do gr√°fico. N√£o liste os dados novamente."""
                else:
                    prompt_final = f"""A pergunta foi: "{prompt}". O resultado da an√°lise dos dados foi: {resultado_analise}. Com base nesse resultado, formule uma resposta amig√°vel e direta."""
                
                response = st.session_state.chat.send_message([prompt, response_container.markdown(f"Analisando os dados...")])
                response_text = response.text
                response_container.markdown(response_text)
    else:
        # --- Modo Chatbot Geral (CORRE√á√ÉO) ---
        # Se nenhum arquivo for carregado, apenas converse normalmente
        response = st.session_state.chat.send_message(prompt)
        response_text = response.text
        with st.chat_message("assistant"):
            st.markdown(response_text)
