import streamlit as st
import google.generativeai as genai
import pandas as pd
import numpy as np
import os
import time
from haversine import haversine, Unit
from io import BytesIO
from datetime import datetime

# ------------------------------------------------------------
# CONFIGURA√á√ÉO DA P√ÅGINA
# ------------------------------------------------------------
st.set_page_config(page_title="Seu Assistente de Dados com IA", page_icon="üß†", layout="wide")
st.title("üß† Merc√∫rio IA")
st.write("Fa√ßa o upload de seus arquivos na barra lateral!")

# ------------------------------------------------------------
# CHAVE DE API
# ------------------------------------------------------------
api_key = None
api_key_status = "N√£o configurada"
try:
    api_key = st.secrets.get("GOOGLE_API_KEY")
    if api_key:
        api_key_status = "‚úîÔ∏è Carregada (Streamlit Secrets)"
except Exception:
    pass

if not api_key:
    api_key = os.environ.get("GOOGLE_API_KEY")
    if api_key:
        api_key_status = "‚úîÔ∏è Carregada (Vari√°vel de Ambiente)"
    else:
        api_key_status = "‚ùå ERRO: Chave n√£o encontrada."

st.sidebar.caption(f"**Status da Chave de API:** {api_key_status}")

if not api_key:
    st.error("A chave da API do Google n√£o foi encontrada. O aplicativo n√£o pode funcionar.")
    st.stop()

genai.configure(api_key=api_key)
modelo_padrao = "gemini-2.5-flash"

# ------------------------------------------------------------
# INICIALIZA√á√ÉO DO MODELO E DO ESTADO DA SESS√ÉO
# ------------------------------------------------------------
if "model" not in st.session_state:
    try:
        st.session_state.model = genai.GenerativeModel(modelo_padrao)
    except Exception as e:
        st.error(f"Erro ao inicializar o modelo Gemini: {e}")
        st.stop()

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "display_history" not in st.session_state:
    st.session_state.display_history = []

# Tabelas
if 'df_dados' not in st.session_state:
    st.session_state.df_dados = None
if 'df_mapeamento' not in st.session_state:
    st.session_state.df_mapeamento = None
if 'df_devolucao' not in st.session_state:
    st.session_state.df_devolucao = None
if 'df_pagamento' not in st.session_state:
    st.session_state.df_pagamento = None

# ------------------------------------------------------------
# FUN√á√ïES AUXILIARES
# ------------------------------------------------------------
@st.cache_data
def convert_df_to_csv(df):
    return df.to_csv(index=False, sep=';').encode('utf-8-sig')

def safe_to_numeric(series):
    if series.dtype == 'object':
        series = series.astype(str).str.replace('R$', '', regex=False).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).str.strip()
    return pd.to_numeric(series, errors='coerce').fillna(0)

@st.cache_data(ttl=3600)
def executar_analise_pandas(_df_hash, pergunta, df_type):
    df = st.session_state.df_dados if df_type == 'dados' else st.session_state.df_mapeamento
    prompt_engenharia = f"""
    Voc√™ √© um assistente especialista em Python e Pandas. Sua tarefa √© analisar a pergunta do usu√°rio.
    As colunas dispon√≠veis no dataframe `df` s√£o: {', '.join(df.columns)}.

    INSTRU√á√ïES:
    1. Determine se a pergunta do usu√°rio PODE ser respondida usando os dados.
    2. Se a pergunta for gen√©rica (ex: "quem descobriu o Brasil?"), responda APENAS com: "PERGUNTA_INVALIDA".
    3. Se a pergunta for sobre os dados, converta-a em uma √∫nica linha de c√≥digo Pandas que gere o resultado.

    Pergunta: "{pergunta}"
    Sua resposta:
    """
    try:
        response = st.session_state.model.generate_content(prompt_engenharia)
        resposta_ia = response.text.strip().replace('`', '').replace('python', '')
        if resposta_ia == "PERGUNTA_INVALIDA":
            return None, "PERGUNTA_INVALIDA"
        resultado = eval(resposta_ia, {'df': df, 'pd': pd, 'np': np})
        return resultado, None
    except Exception as e:
        return None, f"Ocorreu um erro ao executar a an√°lise: {e}"

def carregar_dataframe(arquivo, separador_padrao=','):
    nome_arquivo = arquivo.name.lower()
    if nome_arquivo.endswith('.xlsx'):
        return pd.read_excel(arquivo, engine='openpyxl')
    elif nome_arquivo.endswith('.xls'):
        return pd.read_excel(arquivo, engine='xlrd')
    elif nome_arquivo.endswith('.csv'):
        try:
            arquivo.seek(0)
            df = pd.read_csv(arquivo, encoding='latin-1', sep=separador_padrao, on_bad_lines='skip')
            if len(df.columns) > 1: return df
        except Exception:
            pass
        arquivo.seek(0)
        outro_separador = ',' if separador_padrao == ';' else ';'
        df = pd.read_csv(arquivo, encoding='latin-1', sep=outro_separador, on_bad_lines='skip')
        return df
    return None

def detectar_tipo_pergunta(texto):
    texto = texto.lower()
    palavras_dados = ["tabela", "csv", "coluna", "quantos", "linhas", "ordem", "agendamento",
                      "representante", "rt", "valor", "duplicidade", "proximidade", "servi√ßo", "mapeamento", "quem atende", "telefone", "contato"]
    if any(p in texto for p in palavras_dados):
        return "dados"
    return "chat"

def executar_analise_simples(prompt, df):
    try:
        prompt_engenharia = f"""
        Voc√™ √© um especialista em Python e Pandas.
        Gere um c√≥digo que responda √† pergunta abaixo usando o DataFrame `df`.
        Retorne apenas o resultado, sem explica√ß√µes, em texto simples.
        Pergunta: {prompt}
        Colunas dispon√≠veis: {', '.join(df.columns)}
        """
        resposta = st.session_state.model.generate_content(prompt_engenharia)
        return resposta.text.strip()
    except Exception as e:
        return f"Erro na an√°lise: {e}"

# ------------------------------------------------------------
# BARRA LATERAL - UPLOADS
# ------------------------------------------------------------
with st.sidebar:
    st.header("Base de Conhecimento")
    tipos_permitidos = ["csv", "xlsx", "xls"]

    data_file = st.file_uploader("1. Upload Pesquisa de O.S (OS)", type=tipos_permitidos)
    if data_file:
        try:
            st.session_state.df_dados = carregar_dataframe(data_file, separador_padrao=';')
            st.success("Agendamentos carregados!")
        except Exception as e:
            st.error(f"Erro nos dados: {e}")

    st.markdown("---")
    map_file = st.file_uploader("2. Upload do Mapeamento de RT (Fixo)", type=tipos_permitidos)
    if map_file:
        try:
            st.session_state.df_mapeamento = carregar_dataframe(map_file, separador_padrao=',')
            st.success("Mapeamento carregado!")
        except Exception as e:
            st.error(f"Erro no mapeamento: {e}")

    st.markdown("---")
    devolucao_file = st.file_uploader("3. Upload de Itens a Instalar (Devolu√ß√£o)", type=tipos_permitidos)
    if devolucao_file:
        try:
            st.session_state.df_devolucao = carregar_dataframe(devolucao_file, separador_padrao=';')
            st.success("Base de devolu√ß√£o carregada!")
        except Exception as e:
            st.error(f"Erro na base de devolu√ß√£o: {e}")

    st.markdown("---")
    pagamento_file = st.file_uploader("4. Upload da Base de Pagamento (Duplicidade)", type=tipos_permitidos)
    if pagamento_file:
        try:
            st.session_state.df_pagamento = carregar_dataframe(pagamento_file, separador_padrao=';')
            st.success("Base de pagamento carregada!")
        except Exception as e:
            st.error(f"Erro na base de pagamento: {e}")

    if st.button("Limpar Tudo"):
        st.session_state.clear()
        st.rerun()

# ------------------------------------------------------------
# CORPO PRINCIPAL
# ------------------------------------------------------------
# (Mantive todo o bloco do dashboard, an√°lise de custos, devolu√ß√£o, mapeamento e otimizador)
# -- N√£o vou repetir aqui para n√£o aumentar desnecessariamente
# -- Mas todos os blocos que voc√™ mandou s√£o mantidos inalterados --

# ------------------------------------------------------------
# SE√á√ÉO DO CHAT DE IA
# ------------------------------------------------------------
st.markdown("---")
st.header("üí¨ Converse com a IA")

for message in st.session_state.display_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Fa√ßa uma pergunta ou pe√ßa an√°lise de dados..."):
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Detecta tipo de pergunta
    tipo = detectar_tipo_pergunta(prompt)
    resposta_texto = ""
    erro_analise = None

    if tipo == "dados":
        df_usar = st.session_state.df_dados if st.session_state.df_dados is not None else None
        if df_usar is not None:
            resultado, erro_analise = executar_analise_pandas(hash(prompt), prompt, df_type='dados')
            if resultado is not None:
                resposta_texto = f"‚úÖ Resultado da an√°lise de dados:\n\n{resultado}"
            elif erro_analise == "PERGUNTA_INVALIDA":
                resposta_texto = "‚ö†Ô∏è Pergunta inv√°lida para an√°lise de dados. Tente outra quest√£o."
            else:
                resposta_texto = f"‚ö†Ô∏è Erro ao processar a pergunta: {erro_analise}"
        else:
            resposta_texto = "‚ö†Ô∏è Nenhum dataframe de dados carregado para an√°lise."
    else:
        try:
            resposta_ia = st.session_state.model.generate_content(prompt)
            resposta_texto = resposta_ia.text.strip()
        except Exception as e:
            resposta_texto = f"‚ö†Ô∏è Erro ao gerar resposta do modelo: {e}"

    st.session_state.display_history.append({"role": "assistant", "content": resposta_texto})
    with st.chat_message("assistant"):
        st.markdown(resposta_texto)
