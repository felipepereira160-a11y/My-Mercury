import streamlit as st
import google.generativeai as genai
import pandas as pd

# Configura o t√≠tulo da p√°gina, layout e um √≠cone
st.set_page_config(
    page_title="Seu Analista de Dados com IA",
    page_icon="üìä",
    layout="wide"
)

# --- T√≠tulo Principal ---
st.title("üìä Mercury Fk")
st.write("Fa√ßa o upload de um arquivo CSV ou XLSX na barra lateral e comece a fazer perguntas!")

# --- Configura√ß√£o da API Key ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except Exception as e:
    st.error("Chave de API do Google n√£o configurada. Por favor, adicione-a aos segredos do seu app no Streamlit.")
    st.stop()

# --- Barra Lateral para Upload ---
with st.sidebar:
    st.header("Adicionar Conhecimento")
    uploaded_file = st.sidebar.file_uploader(
        "Fa√ßa o upload de um arquivo CSV ou XLSX", 
        type=["csv", "xlsx"]
    )

    if 'dataframe' not in st.session_state:
        st.session_state.dataframe = None

    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file, encoding='latin-1', sep=';', on_bad_lines='skip')
            elif uploaded_file.name.endswith('.xlsx'):
                df = pd.read_excel(uploaded_file, engine='openpyxl')
            st.session_state.dataframe = df
            st.success("Arquivo carregado com sucesso!")
        except Exception as e:
            st.error(f"Erro ao ler o arquivo: {e}")
    
    if st.button("Limpar Arquivo e Chat"):
        st.session_state.dataframe = None
        st.session_state.chat = model.start_chat(history=[])
        st.rerun()

# --- Corpo Principal da Aplica√ß√£o ---
model = genai.GenerativeModel('gemini-pro-latest')
if "chat" not in st.session_state:
    st.session_state.chat = model.start_chat(history=[])

if st.session_state.dataframe is not None:
    df = st.session_state.dataframe
    st.header("Dashboard do Arquivo")
    col1, col2, col3 = st.columns(3)
    col1.metric("Total de Linhas", f"{df.shape[0]:,}".replace(",", "."), "linhas")
    col2.metric("Total de Colunas", f"{df.shape[1]}", "colunas")
    coluna_cliente = next((col for col in df.columns if 'cliente' in col.lower()), None)
    if coluna_cliente:
        clientes_unicos = df[coluna_cliente].nunique()
        col3.metric("Clientes √önicos", f"{clientes_unicos}", "clientes")
    with st.expander("Clique aqui para ver a pr√©-visualiza√ß√£o dos dados"):
        st.dataframe(df)
    st.header("Converse com seus Dados")

for message in st.session_state.chat.history:
    role = "assistant" if message.role == 'model' else message.role
    with st.chat_message(role):
        st.markdown(message.parts[0].text)

def executar_analise_pandas(df, pergunta):
    # --- ALTERA√á√ÉO 1: Adicionando dicas para a IA ---
    prompt_engenharia = f"""
    Voc√™ √© um assistente especialista em Python e Pandas. Sua tarefa √© converter uma pergunta em uma √∫nica linha de c√≥digo Pandas que a responda.
    O dataframe est√° na vari√°vel `df`.
    Aqui est√£o as primeiras linhas do dataframe: {df.head().to_string()}

    DICAS IMPORTANTES:
    - Se a pergunta for sobre ordens "Agendadas", "Realizadas", "Reagendadas" ou "N√£o realizadas", voc√™ deve filtrar a coluna 'Status' pelos valores correspondentes (ex: 'Agendada', 'Realizada', etc.).

    Pergunta do usu√°rio: "{pergunta}"
    
    Baseado na pergunta e nas dicas, gere apenas a linha de c√≥digo Pandas necess√°ria. Se a pergunta pedir um gr√°fico, gere o c√≥digo que calcula os dados para o gr√°fico (ex: value_counts()).
    """
    try:
        code_response = genai.GenerativeModel('gemini-pro-latest').generate_content(prompt_engenharia)
        codigo_pandas = code_response.text.strip().replace('`', '').replace('python', '').strip()
        resultado = eval(codigo_pandas, {'df': df, 'pd': pd})
        return resultado, None
    except Exception as e:
        return None, f"Ocorreu um erro ao executar a an√°lise: {e}"

if prompt := st.chat_input("Fa√ßa uma pergunta sobre seus dados..."):
    with st.chat_message("user"):
        st.markdown(prompt)
    
    if st.session_state.dataframe is not None:
        resultado_analise, erro = executar_analise_pandas(st.session_state.dataframe, prompt)
        
        if erro:
            st.error(erro)
            response_text = "Desculpe, n√£o consegui analisar os dados. Tente uma pergunta mais simples ou verifique o arquivo."
            # Adiciona a mensagem de erro ao hist√≥rico para exibi√ß√£o
            st.session_state.chat.history.append({'role': 'assistant', 'parts': [{'text': response_text}]})
            with st.chat_message("assistant"):
                st.markdown(response_text)
        else:
            response_container = st.chat_message("assistant")
            with response_container:
                # --- ALTERA√á√ÉO 2: L√≥gica aprimorada para exibir gr√°ficos ---
                if isinstance(resultado_analise, (pd.Series, pd.DataFrame)) and len(resultado_analise) > 1:
                    st.write("Aqui est√° uma visualiza√ß√£o para sua pergunta:")
                    st.bar_chart(resultado_analise)
                    prompt_final = f"""
                    A pergunta do usu√°rio foi: "{prompt}"
                    Para responder, um gr√°fico de barras j√° foi exibido na tela mostrando os dados a seguir:
                    ---
                    {resultado_analise.to_string()}
                    ---
                    Sua tarefa √© apenas escrever uma breve an√°lise ou um resumo do que o gr√°fico est√° mostrando. N√£o liste os dados novamente. Apenas interprete as informa√ß√µes de forma amig√°vel. Por exemplo: 'O gr√°fico mostra que a cidade com mais agendamentos √© X, seguida por Y.'
                    """
                else:
                    prompt_final = f"""
                    A pergunta foi: "{prompt}"
                    O resultado da an√°lise dos dados foi: {resultado_analise}
                    Com base nesse resultado, formule uma resposta amig√°vel, direta e clara para o usu√°rio.
                    """
                
                response = st.session_state.chat.send_message(prompt_final)
                response_text = response.text
                st.markdown(response_text)

    else:
        response_text = "Por favor, carregue um arquivo CSV ou XLSX na barra lateral para come√ßar a an√°lise."
        with st.chat_message("assistant"):
            st.markdown(response_text)
