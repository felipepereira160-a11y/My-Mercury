import streamlit as st
import google.generativeai as genai
import pandas as pd

# Configura o t√≠tulo da p√°gina, layout e um √≠cone
st.set_page_config(
    page_title="Seu Analista de Dados com IA",
    page_icon="üìä",
    layout="wide"  # Usa a largura total da p√°gina
)

# --- T√≠tulo Principal ---
st.title("üìä Seu Analista de Dados com IA")
st.write("Fa√ßa o upload de um arquivo CSV na barra lateral e comece a fazer perguntas!")

# --- Configura√ß√£o da API Key ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except Exception as e:
    st.error("Chave de API do Google n√£o configurada. Por favor, adicione-a aos segredos do seu app no Streamlit.")
    st.stop()

# --- Barra Lateral para Upload ---
with st.sidebar:
    st.header("Adicionar Conhecimento")
    uploaded_file = st.sidebar.file_uploader("Fa√ßa o upload de um arquivo CSV", type=["csv"])

    if 'dataframe' not in st.session_state:
        st.session_state.dataframe = None

    if uploaded_file is not None:
        try:
            # Tenta ler o CSV com diferentes configura√ß√µes
            st.session_state.dataframe = pd.read_csv(uploaded_file, encoding='latin-1', sep=';')
            st.success("Arquivo carregado com sucesso!")
        except Exception:
            try:
                uploaded_file.seek(0)
                st.session_state.dataframe = pd.read_csv(uploaded_file, encoding='latin-1', sep=',')
                st.success("Arquivo carregado com sucesso!")
            except Exception as e2:
                st.error(f"Erro ao ler o arquivo: {e2}")
    
    # Adiciona um bot√£o para limpar o arquivo e o chat
    if st.button("Limpar Arquivo e Chat"):
        st.session_state.dataframe = None
        st.session_state.chat = model.start_chat(history=[])
        st.rerun()

# --- Corpo Principal da Aplica√ß√£o ---
# Inicializa√ß√£o do Modelo e do Chat
model = genai.GenerativeModel('gemini-pro-latest')
if "chat" not in st.session_state:
    st.session_state.chat = model.start_chat(history=[])

# Se um arquivo foi carregado, mostra o dashboard e o chat
if st.session_state.dataframe is not None:
    df = st.session_state.dataframe
    
    st.header("Dashboard do Arquivo")
    col1, col2, col3 = st.columns(3)
    col1.metric("Total de Linhas", f"{df.shape[0]:,}".replace(",", "."), "linhas")
    col2.metric("Total de Colunas", f"{df.shape[1]}", "colunas")
    
    # Calcula o n√∫mero de clientes √∫nicos, se a coluna existir
    if 'ClienteNome' in df.columns:
        clientes_unicos = df['ClienteNome'].nunique()
        col3.metric("Clientes √önicos", f"{clientes_unicos}", "clientes")
    
    with st.expander("Clique aqui para ver a pr√©-visualiza√ß√£o dos dados"):
        st.dataframe(df)
    
    st.header("Converse com seus Dados")

# Exibi√ß√£o do Hist√≥rico da Conversa
for message in st.session_state.chat.history:
    role = "assistant" if message.role == 'model' else message.role
    with st.chat_message(role):
        st.markdown(message.parts[0].text)

# --- Fun√ß√£o para gerar e executar c√≥digo Pandas ---
def executar_analise_pandas(df, pergunta):
    prompt_engenharia = f"""
    Voc√™ √© um assistente especialista em Python e Pandas. Sua tarefa √© converter uma pergunta em uma √∫nica linha de c√≥digo Pandas que a responda.
    O dataframe est√° na vari√°vel `df`.
    Aqui est√£o as primeiras linhas do dataframe para refer√™ncia das colunas: {df.head().to_string()}
    Pergunta do usu√°rio: "{pergunta}"
    Baseado na pergunta, gere apenas a linha de c√≥digo Pandas necess√°ria.
    """
    try:
        code_response = genai.GenerativeModel('gemini-pro-latest').generate_content(prompt_engenharia)
        codigo_pandas = code_response.text.strip().replace('`', '').replace('python', '').strip()
        resultado = eval(codigo_pandas, {'df': df, 'pd': pd})
        return resultado, None
    except Exception as e:
        return None, f"Ocorreu um erro ao executar a an√°lise: {e}"

# --- Entrada do Usu√°rio ---
if prompt := st.chat_input("Fa√ßa uma pergunta sobre seus dados..."):
    with st.chat_message("user"):
        st.markdown(prompt)
    
    if st.session_state.dataframe is not None:
        resultado_analise, erro = executar_analise_pandas(st.session_state.dataframe, prompt)
        
        if erro:
            st.error(erro)
            response_text = "Desculpe, n√£o consegui analisar os dados. Tente uma pergunta mais simples ou verifique o arquivo."
        else:
            prompt_final = f"""
            A pergunta foi: "{prompt}"
            O resultado da an√°lise dos dados foi: {resultado_analise}
            Com base nesse resultado, formule uma resposta amig√°vel, direta e clara para o usu√°rio.
            """
            response = st.session_state.chat.send_message(prompt_final)
            response_text = response.text
    else:
        response_text = "Por favor, carregue um arquivo CSV na barra lateral para come√ßar a an√°lise."

    with st.chat_message("assistant"):
        st.markdown(response_text)
