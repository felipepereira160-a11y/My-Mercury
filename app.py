import streamlit as st
import google.generativeai as genai
import pandas as pd
import numpy as np
import os
from datetime import datetime
from haversine import haversine, Unit

# ============================================================
# CONFIGURA√á√ÉO GERAL DO APP
# ============================================================
st.set_page_config(page_title="Merc√∫rio IA", page_icon="üß†", layout="wide")
st.title("üß† Merc√∫rio IA")
st.write("Fa√ßa o upload de seus arquivos na barra lateral e converse com a IA!")

# ------------------------------------------------------------
# CONFIGURA√á√ÉO DA CHAVE DE API
# ------------------------------------------------------------
api_key = st.secrets.get("GOOGLE_API_KEY") or os.environ.get("GOOGLE_API_KEY")
api_key_status = "‚úîÔ∏è Carregada" if api_key else "‚ùå ERRO: Chave n√£o encontrada."
# --- Configura√ß√£o do modelo atualizado ---
if api_key:
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5')  # Vers√£o atualizada da API
    except Exception as e:
        st.error(f"Erro ao configurar a API do Google: {e}")
        st.stop()
else:
    st.error("A chave da API do Google n√£o foi encontrada. O aplicativo n√£o pode funcionar.")
    st.stop()

# --- Inicializa√ß√£o do estado do chat ---
if "chat" not in st.session_state and model:
    st.session_state.chat = model.start_chat()  # start_chat() continua v√°lido

# --- Fun√ß√£o de an√°lise de Pandas atualizada ---
@st.cache_data(ttl=3600)
def executar_analise_pandas(_df_hash, pergunta, df_type):
    df = st.session_state.df_dados if df_type == 'dados' else st.session_state.df_mapeamento
    prompt_engenharia = f"""
Voc√™ √© um assistente especialista em Python e Pandas. Sua tarefa √© analisar a pergunta do usu√°rio.
As colunas dispon√≠veis no dataframe `df` s√£o: {', '.join(df.columns)}.

INSTRU√á√ïES:
1. Determine se a pergunta do usu√°rio PODE ser respondida usando os dados.
2. Se a pergunta for gen√©rica (ex: "quem descobriu o Brasil?"), responda APENAS com: "PERGUNTA_INVALIDA".
3. Se a pergunta for sobre os dados, converta-a em uma √∫nica linha de c√≥digo Pandas que gere o resultado.

Pergunta: "{pergunta}"
Sua resposta:
"""
    try:
        response = model.generate_text(input=prompt_engenharia, max_output_tokens=800)
        resposta_ia = response.output_text.strip().replace('`', '').replace('python', '')
        if resposta_ia == "PERGUNTA_INVALIDA":
            return None, "PERGUNTA_INVALIDA"
        # Avaliando a resposta com seguran√ßa
        resultado = eval(resposta_ia, {'df': df, 'pd': pd, 'np': np})
        return resultado, None
    except Exception as e:
        return None, f"Ocorreu um erro ao executar a an√°lise: {e}"


# ============================================================
# CHAT INTERATIVO MERC√öRIO IA
# ============================================================
st.markdown("---")
st.header("üí¨ Chat com o Assistente Merc√∫rio IA")

# Exibir hist√≥rico do chat
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Entrada do usu√°rio
if prompt := st.chat_input("Envie uma pergunta ou mensagem..."):
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    tipo = detectar_tipo_pergunta(prompt)
    resposta_final = ""

    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            if tipo == "dados":
                df = st.session_state.df_dados or st.session_state.df_mapeamento
                if df is not None:
                    resposta_final = executar_analise(prompt, df)
                else:
                    resposta_final = "Nenhum arquivo foi carregado ainda para an√°lise de dados."
            else:
                resposta = st.session_state.model.generate_content(prompt)
                resposta_final = resposta.text.strip()

            st.markdown(resposta_final)

    st.session_state.chat_history.append({"role": "assistant", "content": resposta_final})
