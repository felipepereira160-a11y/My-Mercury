# ==============================================================================
# MERC√öRIO IA - C√ìDIGO COMPLETO E REATORADO
# Vers√£o: 2.1
# Modelo IA: Gemini 1.5 Pro (Configura√ß√£o Centralizada)
# Autor: Mercurio
# ==============================================================================

import streamlit as st
import google.generativeai as genai
import pandas as pd
import numpy as np
import os
from haversine import haversine, Unit
from io import BytesIO
from datetime import datetime

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(page_title="Merc√∫rio IA", page_icon="üß†", layout="wide")

# --- T√≠tulo ---
st.title("üß† Merc√∫rio IA")
st.write("Fa√ßa o upload de seus arquivos na barra lateral para iniciar a an√°lise!")

# --- CONFIGURA√á√ÉO CENTRAL DO MODELO DE IA ---
# Para trocar o modelo (ex: para uma vers√£o mais r√°pida como "gemini-1.5-flash-latest"),
# altere APENAS esta linha.
GEMINI_MODEL = "gemini-1.5-pro-latest"

# --- L√≥gica robusta para carregar a chave da API ---
# Tenta carregar dos secrets do Streamlit, se n√£o encontrar, tenta das vari√°veis de ambiente.
api_key = st.secrets.get("GOOGLE_API_KEY") or os.environ.get("GOOGLE_API_KEY")

# --- Valida√ß√£o da API e Inicializa√ß√£o do Modelo ---
model = None
with st.sidebar:
    st.header("Configura√ß√£o")
    if api_key:
        st.caption(f"‚úîÔ∏è Chave de API carregada.")
        st.caption(f"**Modelo de IA:** `{GEMINI_MODEL}`")
        try:
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(GEMINI_MODEL)
        except Exception as e:
            st.error(f"Erro ao configurar a API do Google: {e}")
            st.stop()
    else:
        st.error("‚ùå Chave de API n√£o encontrada.")
        st.stop()

# --- Inicializa√ß√£o do Estado da Sess√£o (de forma otimizada) ---
if "chat" not in st.session_state and model:
    st.session_state.chat = model.start_chat(history=[])
if "display_history" not in st.session_state:
    st.session_state.display_history = []

for key in ['df_dados', 'df_mapeamento', 'df_devolucao', 'df_pagamento']:
    if key not in st.session_state:
        st.session_state[key] = None


# --- Fun√ß√µes Auxiliares ---
@st.cache_data
def convert_df_to_csv(df):
    """Converte um DataFrame para CSV otimizado para Excel em portugu√™s."""
    return df.to_csv(index=False, sep=';').encode('utf-8-sig')

def safe_to_numeric(series):
    """Converte uma s√©rie para num√©rico de forma robusta, limpando s√≠mbolos monet√°rios e de pontua√ß√£o."""
    if pd.api.types.is_string_dtype(series):
        series = series.str.replace('R$', '', regex=False).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).str.strip()
    return pd.to_numeric(series, errors='coerce').fillna(0)

@st.cache_data(ttl=3600)
def executar_analise_pandas(_df_hash, pergunta, df_type):
    """Usa a IA para converter uma pergunta em c√≥digo Pandas e execut√°-lo."""
    df_map = {'dados': st.session_state.df_dados, 'mapeamento': st.session_state.df_mapeamento}
    df = df_map.get(df_type)
    if df is None:
        return None, "DataFrame n√£o encontrado no estado da sess√£o."

    prompt_engenharia = f"""
    Voc√™ √© um assistente especialista em Python e Pandas. Sua tarefa √© analisar a pergunta do usu√°rio.
    As colunas dispon√≠veis no dataframe `df` s√£o: {', '.join(df.columns)}.

    INSTRU√á√ïES:
    1. Determine se a pergunta do usu√°rio PODE ser respondida usando os dados.
    2. Se a pergunta for gen√©rica (ex: "quem descobriu o Brasil?"), responda APENAS com: "PERGUNTA_INVALIDA".
    3. Se a pergunta for sobre os dados, converta-a em uma √∫nica linha de c√≥digo Pandas que gere o resultado. O c√≥digo n√£o deve conter a palavra 'python' nem acentos graves (`).

    Pergunta: "{pergunta}"
    Sua resposta:
    """
    try:
        local_model = genai.GenerativeModel(GEMINI_MODEL)
        response = local_model.generate_content(prompt_engenharia)
        resposta_ia = response.text.strip()
        
        if resposta_ia == "PERGUNTA_INVALIDA":
            return None, "PERGUNTA_INVALIDA"
            
        resultado = eval(resposta_ia, {'df': df, 'pd': pd, 'np': np})
        return resultado, None
    except Exception as e:
        return None, f"Ocorreu um erro ao executar a an√°lise: {e}"

def carregar_dataframe(arquivo):
    """Carrega arquivos CSV, XLSX ou XLS de forma inteligente."""
    nome_arquivo = arquivo.name.lower()
    try:
        if nome_arquivo.endswith('.xlsx'):
            return pd.read_excel(arquivo, engine='openpyxl')
        elif nome_arquivo.endswith('.xls'):
            return pd.read_excel(arquivo, engine='xlrd')
        elif nome_arquivo.endswith('.csv'):
            arquivo.seek(0)
            df = pd.read_csv(arquivo, encoding='latin-1', sep=';', on_bad_lines='warn')
            if len(df.columns) <= 1:
                arquivo.seek(0)
                df = pd.read_csv(arquivo, encoding='latin-1', sep=',', on_bad_lines='warn')
            return df
    except Exception as e:
        st.error(f"Erro ao ler o arquivo {arquivo.name}: {e}")
    return None

# --- Barra Lateral (Sidebar) ---
with st.sidebar:
    st.header("Base de Conhecimento")
    tipos_permitidos = ["csv", "xlsx", "xls"]
    
    arquivos_config = {
        'df_dados': "1. Upload de Agendamentos (OS)",
        'df_mapeamento': "2. Upload do Mapeamento de RT",
        'df_devolucao': "3. Upload de Itens a Instalar (Dev.)",
        'df_pagamento': "4. Upload Base de Pagamento (Duplic.)"
    }
    
    for key, label in arquivos_config.items():
        uploaded_file = st.file_uploader(label, type=tipos_permitidos, key=f"upload_{key}")
        if uploaded_file:
            st.session_state[key] = carregar_dataframe(uploaded_file)
            if st.session_state[key] is not None:
                st.caption(f"‚úîÔ∏è {label.split('(')[0].strip()} carregado.")
        st.markdown("---")

    if st.button("üóëÔ∏è Limpar Tudo e Reiniciar"):
        st.session_state.clear()
        st.rerun()

# ==============================================================================
# --- Corpo Principal da Aplica√ß√£o ---
# ==============================================================================

# [COLE AQUI OS SEUS M√ìDULOS DE AN√ÅLISE 1 A 5]
# Os m√≥dulos de Dashboard, Analisador de Custos, Devolu√ß√£o, Mapeamento e 
# Otimizador permanecem os mesmos. Cole-os aqui.
# Para manter a resposta concisa, eles foram omitidos.

# --- M√ìDULO 6: CHAT COM A IA (VERS√ÉO REFEITA) ---
st.markdown("---")
st.header("üí¨ Converse com a IA")

for message in st.session_state.display_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Fa√ßa uma pergunta espec√≠fica sobre os dados ou converse comigo..."):
    st.session_state.display_history.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        response_text = ""
        contexto_analise = None

        # Determina o contexto da pergunta para an√°lise de dados
        keywords_mapeamento = ["quem atende", "representante de", "contato do rt", "telefone de", "rt para", "mapeamento"]
        if any(keyword in prompt.lower() for keyword in keywords_mapeamento) and st.session_state.df_mapeamento is not None:
            contexto_analise = 'mapeamento'
        elif st.session_state.df_dados is not None:
            # Se n√£o for sobre mapeamento, mas houver dados de OS, assume que a an√°lise √© sobre eles.
            contexto_analise = 'dados'

        # Tenta a an√°lise de dados primeiro, se houver um contexto
        if contexto_analise:
            with st.spinner(f"Analisando no arquivo de '{contexto_analise}'..."):
                current_df = st.session_state[f"df_{contexto_analise}"]
                df_hash = pd.util.hash_pandas_object(current_df, index=True).sum()
                resultado_analise, erro = executar_analise_pandas(df_hash, prompt, contexto_analise)

                if erro == "PERGUNTA_INVALIDA":
                    # Se a IA julgar que n√£o √© sobre dados, anula o contexto para cair no chat geral
                    contexto_analise = None 
                elif erro:
                    st.error(erro)
                    response_text = "Desculpe, encontrei um erro ao tentar analisar sua pergunta nos dados."
                elif resultado_analise is not None:
                    if isinstance(resultado_analise, (pd.Series, pd.DataFrame)):
                        st.write(f"Resultado da sua consulta nos dados de '{contexto_analise}':")
                        st.dataframe(resultado_analise)
                        response_text = "A informa√ß√£o que voc√™ pediu est√° na tabela acima."
                    else:
                        response_text = f"O resultado da sua an√°lise √©: **{resultado_analise}**"
                    st.markdown(response_text)
        
        # Se n√£o havia contexto para an√°lise, ou a an√°lise falhou, usa o chat geral
        if not contexto_analise and not response_text:
            with st.spinner("Pensando..."):
                try:
                    response = st.session_state.chat.send_message(prompt)
                    response_text = response.text
                    st.markdown(response_text)
                except Exception as e:
                    st.error(f"Ocorreu um erro na comunica√ß√£o com a IA. Detalhe: {e}")
                    response_text = "N√£o consegui processar sua solicita√ß√£o no momento."

    # Adiciona a resposta final ao hist√≥rico, evitando duplicatas
    if response_text:
        st.session_state.display_history.append({"role": "assistant", "content": response_text})
